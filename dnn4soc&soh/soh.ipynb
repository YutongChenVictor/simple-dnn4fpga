{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bb67b45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Loss: 0.0001\n",
      "Epoch [2/3], Loss: 0.0000\n",
      "Epoch [3/3], Loss: 0.0000\n",
      "Average Test Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 设置随机种子以保证可重复性\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# 读取 csv_soh.csv\n",
    "df_soh = pd.read_csv('csv_soh.csv', skiprows=1)  # 跳过第一行（表头）\n",
    "\n",
    "# 提取列\n",
    "labels = torch.tensor(df_soh.iloc[:, 0].values, dtype=torch.float32).view(-1, 1)  # 使用第一列作为标签\n",
    "inputs = torch.tensor(df_soh.iloc[:, 1:3].values, dtype=torch.float32)  # 使用第二和第三列作为输入特征\n",
    "\n",
    "# 将数据集拆分为训练集和测试集（80% 训练，20% 测试）\n",
    "inputs_train, inputs_test, labels_train, labels_test = train_test_split(inputs, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 转换为 PyTorch 数据集\n",
    "train_dataset = TensorDataset(inputs_train, labels_train)\n",
    "test_dataset = TensorDataset(inputs_test, labels_test)\n",
    "\n",
    "# 创建训练集和测试集的 DataLoader\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 定义一个简单的神经网络模型\n",
    "class SimpleDNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleDNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# 实例化模型\n",
    "input_size = 2  # 输入特征的数量\n",
    "hidden_size = 8  # 隐藏层单元的数量\n",
    "output_size = 1  # 输出单元的数量（回归问题通常为1）\n",
    "\n",
    "model = SimpleDNN(input_size, hidden_size, output_size)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 训练循环\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs_batch, labels_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs_batch)\n",
    "        loss = criterion(outputs, labels_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# 测试模型\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_loss = 0.0\n",
    "    predictions = []\n",
    "\n",
    "    # 选择测试集的子集以打印预测\n",
    "    num_samples_to_print = 10\n",
    "    sample_indices = np.random.choice(len(test_loader.dataset), num_samples_to_print, replace=False)\n",
    "\n",
    "    for i, (inputs_batch, labels_batch) in enumerate(test_loader):\n",
    "        outputs = model(inputs_batch)\n",
    "        test_loss += criterion(outputs, labels_batch).item()\n",
    "\n",
    "        # 存储选择子集的预测\n",
    "        if i in sample_indices:\n",
    "            predictions.append((outputs.numpy(), labels_batch.numpy()))\n",
    "\n",
    "    average_test_loss = test_loss / len(test_loader)\n",
    "    print(f'Average Test Loss: {average_test_loss:.4f}')\n",
    "\n",
    "# 打印选择子集的预测和实际值\n",
    "for pred, actual in predictions:\n",
    "    print(f'Prediction: {pred.flatten()}, Actual: {actual.flatten()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fe650af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter name: fc1.weight, Size: torch.Size([8, 2]), Values: Parameter containing:\n",
      "tensor([[ 0.4426,  0.4714],\n",
      "        [-0.2552,  0.5521],\n",
      "        [-0.2313,  0.0666],\n",
      "        [-0.4389,  0.3065],\n",
      "        [ 0.6233, -0.5188],\n",
      "        [ 0.5141,  0.0091],\n",
      "        [ 0.6376,  0.2475],\n",
      "        [ 0.3005, -0.1364]], requires_grad=True)\n",
      "Parameter name: fc1.bias, Size: torch.Size([8]), Values: Parameter containing:\n",
      "tensor([ 0.4351,  0.0093, -0.4065,  0.0758, -0.3258, -0.1990, -0.1471,  0.4288],\n",
      "       requires_grad=True)\n",
      "Parameter name: fc2.weight, Size: torch.Size([1, 8]), Values: Parameter containing:\n",
      "tensor([[-0.1524, -0.0344,  0.0045, -0.0887,  0.0334, -0.2610,  0.4916, -0.2634]],\n",
      "       requires_grad=True)\n",
      "Parameter name: fc2.bias, Size: torch.Size([1]), Values: Parameter containing:\n",
      "tensor([0.3993], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Print model parameters\n",
    "for name, param in model.named_parameters():\n",
    "    print(f'Parameter name: {name}, Size: {param.size()}, Values: {param}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70e0a105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters for fc1 saved to model_parameters\\fc1_params_0.csv\n",
      "Parameters for fc1 saved to model_parameters\\fc1_params_1.csv\n",
      "Parameters for fc2 saved to model_parameters\\fc2_params_2.csv\n",
      "Parameters for fc2 saved to model_parameters\\fc2_params_3.csv\n",
      "Parameters exported successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ... (previous code remains unchanged)\n",
    "\n",
    "# Create a directory to store the parameters CSV files\n",
    "output_dir = 'model_parameters'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save model parameters to CSV files\n",
    "for idx, (name, param) in enumerate(model.named_parameters()):\n",
    "    layer_name = name.split('.')[0]\n",
    "    layer_params = param.detach().numpy().flatten()\n",
    "\n",
    "    # Create a DataFrame and save to CSV\n",
    "    df = pd.DataFrame({f'{layer_name}_param_{i}': layer_params[i] for i in range(len(layer_params))}, index=[0])\n",
    "    csv_path = os.path.join(output_dir, f'{layer_name}_params_{idx}.csv')\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "    print(f'Parameters for {layer_name} saved to {csv_path}')\n",
    "\n",
    "print('Parameters exported successfully.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ec59a749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 17.21403646  16.76178984   0.86294918   8.2621772  -14.63076388\n",
      "   2.01942082  10.18089758  -2.82019202]\n",
      "输出: [0.94816384]\n"
     ]
    }
   ],
   "source": [
    "def relu(x):\n",
    "    return np.max(x, 0)\n",
    "w1 = np.array([[ 0.4426,  0.4714],\n",
    "        [-0.2552,  0.5521],\n",
    "        [-0.2313,  0.0666],\n",
    "        [-0.4389,  0.3065],\n",
    "        [ 0.6233, -0.5188],\n",
    "        [ 0.5141,  0.0091],\n",
    "        [ 0.6376,  0.2475],\n",
    "        [ 0.3005, -0.1364]])\n",
    "w2 = np.array([-0.1524, -0.0344,  0.0045, -0.0887,  0.0334, -0.2610,  0.4916, -0.2634])\n",
    "\n",
    "b1 = np.array([ 0.4351,  0.0093, -0.4065,  0.0758, -0.3258, -0.1990, -0.1471,  0.4288])\n",
    "b2 = np.array([0.3993])\n",
    "\n",
    "label = np.array([0.77])\n",
    "data_in = np.array([3.74739301071869,32.0753931146082])\n",
    "\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(x, 0)\n",
    "\n",
    "# 输入\n",
    "\n",
    "# 第一层计算\n",
    "layer1_output = relu(np.dot(data_in, w1.T) + b1)\n",
    "\n",
    "# 第二层计算\n",
    "output = np.dot(layer1_output, w2) + b2\n",
    "print(np.dot(data_in, w1.T) + b1)\n",
    "# 输出\n",
    "print(\"输出:\", output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a0edc85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 245589 2102093]\n",
      "[0.21418805 0.         0.         0.26227547 0.         0.01922644\n",
      " 0.18083733 0.17988845]\n",
      "[0.37989832]\n"
     ]
    }
   ],
   "source": [
    "a_int = np.round(data_in * 2**16).astype(int)\n",
    "print(a_int)\n",
    "layer1_output = relu(np.dot(a_int, w1_int.T)/2**16 + b1_int)\n",
    "print(layer1_output/2**16)\n",
    "# 第二层计算\n",
    "output = np.dot(layer1_output, w2_int)/2**16 + b2_int\n",
    "print(output/2**16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "220dea97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights_fc1:\n",
      "00000000000000000111000101001110\t29006\n",
      "00000000000000000111100010101110\t30894\n",
      "11111111111111111011111010101011\t-16725\n",
      "00000000000000001000110101010110\t36182\n",
      "11111111111111111100010011001010\t-15158\n",
      "00000000000000000001000100001101\t4365\n",
      "11111111111111111000111110100100\t-28764\n",
      "00000000000000000100111001110111\t20087\n",
      "00000000000000001001111110010001\t40849\n",
      "11111111111111110111101100110000\t-34000\n",
      "00000000000000001000001110011100\t33692\n",
      "00000000000000000000001001010100\t596\n",
      "00000000000000001010001100111010\t41786\n",
      "00000000000000000011111101011100\t16220\n",
      "00000000000000000100110011101110\t19694\n",
      "11111111111111111101110100010101\t-8939\n",
      "\n",
      "bias_fc1:\n",
      "00000000000000000110111101100011\t28515\n",
      "00000000000000000000001001100001\t609\n",
      "11111111111111111001011111110000\t-26640\n",
      "00000000000000000001001101101000\t4968\n",
      "11111111111111111010110010011000\t-21352\n",
      "11111111111111111100110100001110\t-13042\n",
      "11111111111111111101101001011000\t-9640\n",
      "00000000000000000110110111000110\t28102\n",
      "\n",
      "weights_fc2:\n",
      "11111111111111111101100011111100\t-9988\n",
      "11111111111111111111011100110010\t-2254\n",
      "00000000000000000000000100100111\t295\n",
      "11111111111111111110100101001011\t-5813\n",
      "00000000000000000000100010001101\t2189\n",
      "11111111111111111011110100101111\t-17105\n",
      "00000000000000000111110111011001\t32217\n",
      "11111111111111111011110010010010\t-17262\n",
      "\n",
      "bias_fc2:\n",
      "00000000000000000110011000111001\t26169\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "k=16\n",
    "m=32\n",
    "# 定义一个函数将浮点数转换为32位二进制字符串\n",
    "def float_to_bin(num):\n",
    "    # 处理负数的补码表示\n",
    "    if num < 0:\n",
    "        num =  num + 2**m\n",
    "    # 转换为32位二进制字符串\n",
    "    bin_str = bin(num)[2:].zfill(m)\n",
    "    return bin_str\n",
    "\n",
    "# 给定的参数\n",
    "w1 = np.array([[ 0.4426,  0.4714],\n",
    "                [-0.2552,  0.5521],\n",
    "                [-0.2313,  0.0666],\n",
    "                [-0.4389,  0.3065],\n",
    "                [ 0.6233, -0.5188],\n",
    "                [ 0.5141,  0.0091],\n",
    "                [ 0.6376,  0.2475],\n",
    "                [ 0.3005, -0.1364]])\n",
    "\n",
    "w2 = np.array([-0.1524, -0.0344,  0.0045, -0.0887,  0.0334, -0.2610,  0.4916, -0.2634])\n",
    "\n",
    "b1 = np.array([ 0.4351,  0.0093, -0.4065,  0.0758, -0.3258, -0.1990, -0.1471,  0.4288])\n",
    "b2 = np.array([0.3993])\n",
    "\n",
    "# 将浮点数参数转换为32位整数\n",
    "w1_int = np.round(w1 * (2**k)).astype(int)\n",
    "w2_int = np.round(w2 * (2**k)).astype(int)\n",
    "b1_int = np.round(b1 * (2**k)).astype(int)\n",
    "b2_int = np.round(b2 * (2**k)).astype(int)\n",
    "\n",
    "# 打印模型参数的二进制表示\n",
    "print(\"weights_fc1:\")\n",
    "for weights_row in w1_int:\n",
    "    for weight in weights_row:\n",
    "        print(f\"{float_to_bin(weight)}\\t{weight}\")\n",
    "\n",
    "print(\"\\nbias_fc1:\")\n",
    "for bias in b1_int:\n",
    "    print(f\"{float_to_bin(bias)}\\t{bias}\")\n",
    "\n",
    "print(\"\\nweights_fc2:\")\n",
    "for weight in w2_int:\n",
    "    print(f\"{float_to_bin(weight)}\\t{weight}\")\n",
    "\n",
    "print(\"\\nbias_fc2:\")\n",
    "for bias in b2_int:\n",
    "    print(f\"{float_to_bin(bias)}\\t{bias}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fe3953",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
