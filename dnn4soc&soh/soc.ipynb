{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b57e59cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Loss: 0.0000\n",
      "Epoch [2/3], Loss: 0.0000\n",
      "Epoch [3/3], Loss: 0.0000\n",
      "Average Test Loss: 0.0000\n",
      "Prediction: [0.13483045 0.77861094 0.8464161  0.73729646 0.58780944 0.4403585\n",
      " 0.6344154  0.9190117  0.8834994  0.6140028  0.02484199 0.29678282\n",
      " 0.65279496 0.2899476  0.3656505  0.79785573 0.75623894 0.29198918\n",
      " 0.9061254  0.09004435 0.6952137  0.12999138 0.482635   0.40310308\n",
      " 0.8187505  0.08526239 0.6299058  0.20809004 0.45211253 0.6272532\n",
      " 0.48235294 0.1607351 ], Actual: [0.13649239 0.7732586  0.8552144  0.7423858  0.5910727  0.44388345\n",
      " 0.6400017  0.930002   0.8810755  0.61865926 0.01976114 0.29666305\n",
      " 0.6558569  0.29134366 0.36894366 0.79271656 0.75594044 0.2949621\n",
      " 0.9135992  0.08723605 0.697731   0.12856534 0.4738486  0.40004987\n",
      " 0.8245925  0.07997212 0.63056076 0.20268957 0.4491081  0.62663746\n",
      " 0.4793383  0.15517776]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 设置随机种子以保证可重复性\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# 读取 csv_soh.csv\n",
    "df_soh = pd.read_csv('csv_soc.csv', skiprows=1)  # 跳过第一行（表头）\n",
    "\n",
    "# 提取列\n",
    "labels = torch.tensor(df_soh.iloc[:, 0].values, dtype=torch.float32).view(-1, 1)  # 使用第一列作为标签\n",
    "inputs = torch.tensor(df_soh.iloc[:, 1:4].values, dtype=torch.float32)  # 使用第二和第三列作为输入特征\n",
    "\n",
    "# 将数据集拆分为训练集和测试集（80% 训练，20% 测试）\n",
    "inputs_train, inputs_test, labels_train, labels_test = train_test_split(inputs, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 转换为 PyTorch 数据集\n",
    "train_dataset = TensorDataset(inputs_train, labels_train)\n",
    "test_dataset = TensorDataset(inputs_test, labels_test)\n",
    "\n",
    "# 创建训练集和测试集的 DataLoader\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 定义一个简单的神经网络模型\n",
    "class SimpleDNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleDNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# 实例化模型\n",
    "input_size = 3  # 输入特征的数量\n",
    "hidden_size = 8  # 隐藏层单元的数量\n",
    "output_size = 1  # 输出单元的数量（回归问题通常为1）\n",
    "\n",
    "model = SimpleDNN(input_size, hidden_size, output_size)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 训练循环\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs_batch, labels_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs_batch)\n",
    "        loss = criterion(outputs, labels_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# 测试模型\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_loss = 0.0\n",
    "    predictions = []\n",
    "\n",
    "    # 选择测试集的子集以打印预测\n",
    "    num_samples_to_print = 10\n",
    "    sample_indices = np.random.choice(len(test_loader.dataset), num_samples_to_print, replace=False)\n",
    "\n",
    "    for i, (inputs_batch, labels_batch) in enumerate(test_loader):\n",
    "        outputs = model(inputs_batch)\n",
    "        test_loss += criterion(outputs, labels_batch).item()\n",
    "\n",
    "        # 存储选择子集的预测\n",
    "        if i in sample_indices:\n",
    "            predictions.append((outputs.numpy(), labels_batch.numpy()))\n",
    "\n",
    "    average_test_loss = test_loss / len(test_loader)\n",
    "    print(f'Average Test Loss: {average_test_loss:.4f}')\n",
    "\n",
    "# 打印选择子集的预测和实际值\n",
    "for pred, actual in predictions:\n",
    "    print(f'Prediction: {pred.flatten()}, Actual: {actual.flatten()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7e79f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter name: fc1.weight, Size: torch.Size([8, 3]), Values: Parameter containing:\n",
      "tensor([[ 0.4414,  0.4792, -0.1353],\n",
      "        [ 0.6330, -0.0229,  0.1268],\n",
      "        [-0.3608,  0.2586,  0.4942],\n",
      "        [-0.3378,  0.5883,  0.1207],\n",
      "        [ 0.5251,  0.1776,  0.2889],\n",
      "        [ 0.0062,  0.5336,  0.0980],\n",
      "        [-0.2695,  0.1472, -0.2660],\n",
      "        [-0.1478, -0.3153,  0.3683]], requires_grad=True)\n",
      "Parameter name: fc1.bias, Size: torch.Size([8]), Values: Parameter containing:\n",
      "tensor([-0.4557, -0.1982, -0.2170, -0.2935,  0.1176, -0.5139,  0.5214, -0.5453],\n",
      "       requires_grad=True)\n",
      "Parameter name: fc2.weight, Size: torch.Size([1, 8]), Values: Parameter containing:\n",
      "tensor([[ 0.2730,  0.0899, -0.1039,  0.2174,  0.0780,  0.3019,  0.0387, -0.1040]],\n",
      "       requires_grad=True)\n",
      "Parameter name: fc2.bias, Size: torch.Size([1]), Values: Parameter containing:\n",
      "tensor([0.1498], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Print model parameters\n",
    "for name, param in model.named_parameters():\n",
    "    print(f'Parameter name: {name}, Size: {param.size()}, Values: {param}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80556ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights_fc1:\n",
      "00000000000000000111000100000000\t28928\n",
      "00000000000000000111101010101101\t31405\n",
      "11111111111111111101110101100000\t-8864\n",
      "00000000000000001010001000001101\t41485\n",
      "11111111111111111111101000100011\t-1501\n",
      "00000000000000000010000001110101\t8309\n",
      "11111111111111111010001110100010\t-23646\n",
      "00000000000000000100001000110100\t16948\n",
      "00000000000000000111111010000111\t32391\n",
      "11111111111111111010100110000100\t-22140\n",
      "00000000000000001001011010011011\t38555\n",
      "00000000000000000001111011101001\t7913\n",
      "00000000000000001000011001101110\t34414\n",
      "00000000000000000010110101111010\t11642\n",
      "00000000000000000100100111110100\t18932\n",
      "00000000000000000000000110011000\t408\n",
      "00000000000000001000100010011010\t34970\n",
      "00000000000000000001100100010111\t6423\n",
      "11111111111111111011101100000000\t-17664\n",
      "00000000000000000010010110101101\t9645\n",
      "11111111111111111011101111100111\t-17433\n",
      "11111111111111111101101000101010\t-9686\n",
      "11111111111111111010111101000110\t-20666\n",
      "00000000000000000101111001001000\t24136\n",
      "\n",
      "bias_fc1:\n",
      "11111111111111111000101101010100\t-29868\n",
      "11111111111111111100110101000011\t-12989\n",
      "11111111111111111100100001110001\t-14223\n",
      "11111111111111111011010011011101\t-19235\n",
      "00000000000000000001111000011110\t7710\n",
      "11111111111111110111110001110001\t-33679\n",
      "00000000000000001000010101111011\t34171\n",
      "11111111111111110111010001100111\t-35737\n",
      "\n",
      "weights_fc2:\n",
      "00000000000000000100010111100000\t17888\n",
      "00000000000000000001011100000100\t5892\n",
      "11111111111111111110010101101000\t-6808\n",
      "00000000000000000011011110101001\t14249\n",
      "00000000000000000001001111111000\t5112\n",
      "00000000000000000100110101001100\t19788\n",
      "00000000000000000000100111100101\t2533\n",
      "11111111111111111110010101100000\t-6816\n",
      "\n",
      "bias_fc2:\n",
      "00000000000000000010011001011001\t9817\n"
     ]
    }
   ],
   "source": [
    "# 提取模型参数\n",
    "weights_fc1 = model.fc1.weight.data.numpy().flatten() * 2**16\n",
    "bias_fc1 = model.fc1.bias.data.numpy().flatten() * 2**16\n",
    "weights_fc2 = model.fc2.weight.data.numpy().flatten() * 2**16\n",
    "bias_fc2 = model.fc2.bias.data.numpy().flatten() * 2**16\n",
    "\n",
    "# 将参数转换为整数并四舍五入\n",
    "weights_fc1_int = weights_fc1.round().astype(int)\n",
    "bias_fc1_int = bias_fc1.round().astype(int)\n",
    "weights_fc2_int = weights_fc2.round().astype(int)\n",
    "bias_fc2_int = bias_fc2.round().astype(int)\n",
    "\n",
    "# 定义一个函数将浮点数转换为二进制字符串\n",
    "def float_to_bin(num):\n",
    "    # 处理负数的补码表示\n",
    "    if num < 0:\n",
    "        num =  num + 2**32\n",
    "    # 转换为16位二进制字符串\n",
    "    bin_str = bin(num)[2:].zfill(32)\n",
    "    return bin_str\n",
    "\n",
    "# 打印模型参数的二进制表示\n",
    "print(\"weights_fc1:\")\n",
    "for weight in weights_fc1_int:\n",
    "    print(f\"{float_to_bin(weight)}\\t{weight}\")\n",
    "\n",
    "print(\"\\nbias_fc1:\")\n",
    "for bias in bias_fc1_int:\n",
    "    print(f\"{float_to_bin(bias)}\\t{bias}\")\n",
    "\n",
    "print(\"\\nweights_fc2:\")\n",
    "for weight in weights_fc2_int:\n",
    "    print(f\"{float_to_bin(weight)}\\t{weight}\")\n",
    "\n",
    "print(\"\\nbias_fc2:\")\n",
    "for bias in bias_fc2_int:\n",
    "    print(f\"{float_to_bin(bias)}\\t{bias}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c2a9b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.15908554  5.71491805 11.63187671  2.60029178 10.19241183  3.12703084\n",
      " -7.23368629  7.77852496]\n",
      "输出: [0.95041471]\n"
     ]
    }
   ],
   "source": [
    "def relu(x):\n",
    "    return np.max(x, 0)\n",
    "w1 = np.array([[ 0.4414,  0.4792, -0.1353],\n",
    "        [ 0.6330, -0.0229,  0.1268],\n",
    "        [-0.3608,  0.2586,  0.4942],\n",
    "        [-0.3378,  0.5883,  0.1207],\n",
    "        [ 0.5251,  0.1776,  0.2889],\n",
    "        [ 0.0062,  0.5336,  0.0980],\n",
    "        [-0.2695,  0.1472, -0.2660],\n",
    "        [-0.1478, -0.3153,  0.3683]])\n",
    "w2 = np.array([0.2730,  0.0899, -0.1039,  0.2174,  0.0780,  0.3019,  0.0387, -0.1040])\n",
    "\n",
    "b1 = np.array([-0.4557, -0.1982, -0.2170, -0.2935,  0.1176, -0.5139,  0.5214, -0.5453])\n",
    "b2 = np.array([0.1498])\n",
    "\n",
    "label = np.array([0.1498])\n",
    "data_in = np.array([4.205534458467607,1.999356317214453,26])\n",
    "\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(x, 0)\n",
    "\n",
    "# 输入\n",
    "\n",
    "# 第一层计算\n",
    "layer1_output = relu(np.dot(data_in, w1.T) + b1)\n",
    "\n",
    "# 第二层计算\n",
    "output = np.dot(layer1_output, w2) + b2\n",
    "print(np.dot(data_in, w1.T) + b1)\n",
    "# 输出\n",
    "print(\"输出:\", output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aba8eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
